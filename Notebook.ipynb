{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407cad6b",
   "metadata": {},
   "source": [
    "# Importing \n",
    "import the importent Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25af384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(f\"TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}\")\n",
    "\n",
    "# See TensorFlow version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a1906a",
   "metadata": {},
   "source": [
    "Read the files and do some more cleaning such as removing the stoping words and remove the missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff621385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poem_id</th>\n",
       "      <th>poem_text</th>\n",
       "      <th>poem_title</th>\n",
       "      <th>poet_id</th>\n",
       "      <th>poet_cat_أفغانستان</th>\n",
       "      <th>poet_cat_إيران</th>\n",
       "      <th>poet_cat_الأردن</th>\n",
       "      <th>poet_cat_الإمارات</th>\n",
       "      <th>poet_cat_البحرين</th>\n",
       "      <th>poet_cat_الجزائر</th>\n",
       "      <th>...</th>\n",
       "      <th>poet_cat_تونس</th>\n",
       "      <th>poet_cat_سوريا</th>\n",
       "      <th>poet_cat_شعراء العراق والشام</th>\n",
       "      <th>poet_cat_عمان</th>\n",
       "      <th>poet_cat_فلسطين</th>\n",
       "      <th>poet_cat_قطر</th>\n",
       "      <th>poet_cat_لبنان</th>\n",
       "      <th>poet_cat_ليبيا</th>\n",
       "      <th>poet_cat_مصر</th>\n",
       "      <th>poet_cat_موريتانيا</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>عيناك غابتا نخيل ساعه السحر شرفتان يناي عنهما ...</td>\n",
       "      <td>انشوده المطر</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65546</td>\n",
       "      <td>ازال يدي قدحي ياليل اين تفرق الشرب زلت اشربها ...</td>\n",
       "      <td>اقداح احلام</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65561</td>\n",
       "      <td>مقلتيك ارتشفت النجوم وعانقت امالي الايبه وسابق...</td>\n",
       "      <td>هوي</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66170</td>\n",
       "      <td>تزيديه لوعه يلقاك لينسي لديك اكتءابه قربي مقلت...</td>\n",
       "      <td>تزيديه لوعه</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66171</td>\n",
       "      <td>عطرت احلامي الشذي شعرك المسترسل الاسود الجو حو...</td>\n",
       "      <td>عبير</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   poem_id                                          poem_text    poem_title  \\\n",
       "0       21  عيناك غابتا نخيل ساعه السحر شرفتان يناي عنهما ...  انشوده المطر   \n",
       "1    65546  ازال يدي قدحي ياليل اين تفرق الشرب زلت اشربها ...   اقداح احلام   \n",
       "2    65561  مقلتيك ارتشفت النجوم وعانقت امالي الايبه وسابق...           هوي   \n",
       "3    66170  تزيديه لوعه يلقاك لينسي لديك اكتءابه قربي مقلت...   تزيديه لوعه   \n",
       "4    66171  عطرت احلامي الشذي شعرك المسترسل الاسود الجو حو...          عبير   \n",
       "\n",
       "   poet_id  poet_cat_أفغانستان  poet_cat_إيران  poet_cat_الأردن  \\\n",
       "0        2                   0               0                0   \n",
       "1        2                   0               0                0   \n",
       "2        2                   0               0                0   \n",
       "3        2                   0               0                0   \n",
       "4        2                   0               0                0   \n",
       "\n",
       "   poet_cat_الإمارات  poet_cat_البحرين  poet_cat_الجزائر  ...  poet_cat_تونس  \\\n",
       "0                  0                 0                 0  ...              0   \n",
       "1                  0                 0                 0  ...              0   \n",
       "2                  0                 0                 0  ...              0   \n",
       "3                  0                 0                 0  ...              0   \n",
       "4                  0                 0                 0  ...              0   \n",
       "\n",
       "   poet_cat_سوريا  poet_cat_شعراء العراق والشام  poet_cat_عمان  \\\n",
       "0               0                             0              0   \n",
       "1               0                             0              0   \n",
       "2               0                             0              0   \n",
       "3               0                             0              0   \n",
       "4               0                             0              0   \n",
       "\n",
       "   poet_cat_فلسطين  poet_cat_قطر  poet_cat_لبنان  poet_cat_ليبيا  \\\n",
       "0                0             0               0               0   \n",
       "1                0             0               0               0   \n",
       "2                0             0               0               0   \n",
       "3                0             0               0               0   \n",
       "4                0             0               0               0   \n",
       "\n",
       "   poet_cat_مصر  poet_cat_موريتانيا  \n",
       "0             0                   0  \n",
       "1             0                   0  \n",
       "2             0                   0  \n",
       "3             0                   0  \n",
       "4             0                   0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('list.txt','r') as st:\n",
    "    list_stopWords = st.read()\n",
    "list_stopWords = list_stopWords.split('\\n')\n",
    "\n",
    "\n",
    "def stopwords(text):\n",
    "    '''\n",
    "    FUNCATION\n",
    "    drop the arabic stopping words values from the input\n",
    "    and then return the return it\n",
    "    INPUT\n",
    "    text of str data type\n",
    "    OUTPUT\n",
    "    text of str data type\n",
    "    '''\n",
    "    text = ' '.join([word for word in text.split(' ') if word not in list_stopWords])\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"-\", \"\")\n",
    "    text = text.replace(\"--\", \"\")\n",
    "    text = text.replace(\"››\", \"\")\n",
    "    text = text.replace(\"‹‹\", \"\")\n",
    "    text = text.replace(\"‰\", \"\")\n",
    "    text = text.replace(\"••\", \"\")\n",
    "    text = text.replace(\"•\", \"\")\n",
    "    text = text.replace(\"’\", \"\")\n",
    "    text = text.replace(\"‘\", \"\")\n",
    "    text = text.replace(\"|\", \"\")   \n",
    "    text = text.replace(\";\", \"\")  \n",
    "    text = text.replace(\"?\", \"\")  \n",
    "    text = text.replace(\"«\", \"\")  \n",
    "    text = text.replace(\"·\", \"\")  \n",
    "    text = text.replace(\"»\", \"\")  \n",
    "    text = text.replace(\"اء\", \"\")  \n",
    "    text = text.replace(\"ءيه\", \"\")  \n",
    "    text = text.replace(\"ءولا\", \"\")  \n",
    "    text = text.replace(\"ءري\", \"\")  \n",
    "    text = text.replace(\"ءذون\", \"\")  \n",
    "    text = text.replace(\"ءد\", \"\")  \n",
    "\n",
    "    return text\n",
    "    \n",
    "df = pd.read_csv('trainCopy.csv')\n",
    "df.drop(['poet_name', 'Unnamed: 0'], axis=1, inplace = True) # drop useless columns\n",
    "df.poem_text = df.poem_text.str[:2000]# select only the first 2000 charecter in the poem_text\n",
    "df.dropna(inplace=True) # drop the missings \n",
    "df.poem_text = df.poem_text.apply(lambda x:stopwords(x)) #remove the stopping words\n",
    "df.poem_title = df.poem_title.apply(lambda x:stopwords(x)) #remove the stopping words\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59a4b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>poem_id</th>\n",
       "      <th>poem_text</th>\n",
       "      <th>poem_title</th>\n",
       "      <th>poet_cat_البحرين</th>\n",
       "      <th>poet_cat_السعودية</th>\n",
       "      <th>poet_cat_العراق</th>\n",
       "      <th>poet_cat_العصر الأندلسي</th>\n",
       "      <th>poet_cat_العصر العباسي</th>\n",
       "      <th>poet_cat_سوريا</th>\n",
       "      <th>poet_cat_لبنان</th>\n",
       "      <th>poet_cat_مصر</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>28111</td>\n",
       "      <td>اله يعلم حلت دمها وسفكه مستحلا بعدما حرما رايت...</td>\n",
       "      <td>الله يعلم حللت دمها</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28112</td>\n",
       "      <td>وكنا نرجي عيسي محمدا لينقذنا لاعج الضر والبلوي...</td>\n",
       "      <td>وكنا نرجي بعد عيسي محمدا</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>28113</td>\n",
       "      <td>اشكو الي اله حماتي فما يعلم لاقيت سواه عجوز سو...</td>\n",
       "      <td>اشكو الي الله حماتي فما</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28114</td>\n",
       "      <td>قالوا الموفق شيعي فقلت خلاف لناس ظهر وكيف يصبح...</td>\n",
       "      <td>قالوا الموفق شيعي فقلت</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28115</td>\n",
       "      <td>ابو الفضل وابن الفضل انت وتربه فغير بديع ان يك...</td>\n",
       "      <td>الفضل وابن الفضل انت وتربه</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  poem_id                                          poem_text  \\\n",
       "0           0    28111  اله يعلم حلت دمها وسفكه مستحلا بعدما حرما رايت...   \n",
       "1           1    28112  وكنا نرجي عيسي محمدا لينقذنا لاعج الضر والبلوي...   \n",
       "2           2    28113  اشكو الي اله حماتي فما يعلم لاقيت سواه عجوز سو...   \n",
       "3           3    28114  قالوا الموفق شيعي فقلت خلاف لناس ظهر وكيف يصبح...   \n",
       "4           4    28115  ابو الفضل وابن الفضل انت وتربه فغير بديع ان يك...   \n",
       "\n",
       "                   poem_title  poet_cat_البحرين  poet_cat_السعودية  \\\n",
       "0         الله يعلم حللت دمها                 0                  0   \n",
       "1    وكنا نرجي بعد عيسي محمدا                 0                  0   \n",
       "2     اشكو الي الله حماتي فما                 0                  0   \n",
       "3      قالوا الموفق شيعي فقلت                 0                  0   \n",
       "4  الفضل وابن الفضل انت وتربه                 0                  0   \n",
       "\n",
       "   poet_cat_العراق  poet_cat_العصر الأندلسي  poet_cat_العصر العباسي  \\\n",
       "0                0                        0                       1   \n",
       "1                0                        0                       1   \n",
       "2                0                        0                       1   \n",
       "3                0                        0                       1   \n",
       "4                0                        0                       1   \n",
       "\n",
       "   poet_cat_سوريا  poet_cat_لبنان  poet_cat_مصر  \n",
       "0               0               0             0  \n",
       "1               0               0             0  \n",
       "2               0               0             0  \n",
       "3               0               0             0  \n",
       "4               0               0             0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('testCopy.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec4f901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56538, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf4e6f",
   "metadata": {},
   "source": [
    "Count the number of Unique words in the text poems using Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97c166a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredDF = df.groupby('poet_id').filter(lambda x : len(x)>20)\n",
    "len(np.unique(filteredDF.poet_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "337587f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import shuffle\n",
    "# shuffled = shuffle(filteredDF).reset_index()\n",
    "# print(shuffled.shape)\n",
    "# shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1dd0fbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54218, 30)\n"
     ]
    }
   ],
   "source": [
    "dfSample = filteredDF[:]\n",
    "print(dfSample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ea4cb87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/abdulazizalkhonain/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/abdulazizalkhonain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/abdulazizalkhonain/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Using Farasa API to checks the lemmatizer model of arabic words.\n",
    "\n",
    "url = 'https://farasa.qcri.org/webapi/lemmatization/'\n",
    "api_key = \"XXXXXXXXXXXXXX\"\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('omw-1.4')\n",
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok)\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens\n",
    "\n",
    "X = dfSample.poem_text\n",
    "y = dfSample.poet_id\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "tfidf = TfidfTransformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "01263ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36326,)\n",
      "(17892,)\n",
      "173    1379\n",
      "117    1049\n",
      "195    1018\n",
      "247     745\n",
      "263     719\n",
      "       ... \n",
      "254      12\n",
      "271      12\n",
      "589      11\n",
      "595      11\n",
      "523      10\n",
      "Name: poet_id, Length: 389, dtype: int64\n",
      "173    690\n",
      "117    538\n",
      "195    516\n",
      "247    392\n",
      "263    391\n",
      "      ... \n",
      "315      4\n",
      "629      4\n",
      "434      4\n",
      "232      4\n",
      "468      4\n",
      "Name: poet_id, Length: 389, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626fca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts = vect.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "X_test_counts = vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import  confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9907e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_colors = ['#193F48', '#1F505B', '#2C7080', '#388EA2','#4EA4C2', '#51ADC3', '#82ACC4', '#649EAB','#9FC3CB', '#BED6DC', '#CEE0E4', '#DCE9EC']\n",
    "conf_colors.reverse()# to show the colors in the confusion_matrix from thicK to light colors\n",
    "\n",
    "def conf_matrix(actual, predicted):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    sns.heatmap(cm, xticklabels=['predicted_negative', 'predicted_positive'], \n",
    "                yticklabels=['actual_negative', 'actual_positive'], annot=True,\n",
    "                fmt='d', annot_kws={'fontsize':20}, cmap=conf_colors);\n",
    "\n",
    "    true_neg, false_pos = cm[0]\n",
    "    false_neg, true_pos = cm[1]\n",
    "\n",
    "    accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "    precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "    recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "    f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "\n",
    "    cm_results = [accuracy, precision, recall, f1]\n",
    "    return cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c856c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b4859d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Training Score: 92.03980099502488 \n",
      "\n",
      "The Accuracy is : 0.7845117845117845\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict_LR = LR.predict(X_test_tfidf)\n",
    "acc_LR = accuracy_score(y_test, y_predict_LR)\n",
    "print(\"\\nThe Training Score: {} \\n\".format(LR.score(X_train_tfidf,y_train)*100))\n",
    "print('The Accuracy is : {}\\n\\n'.format(acc_LR) )\n",
    "# cm_LR = conf_matrix(y_test, y_predict_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c20bc504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GNB = GaussianNB()\n",
    "GNB.fit(X_train_tfidf.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c7ef0579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Training Score: 100.0 \n",
      "\n",
      "The Accuracy is : 0.8653198653198653\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_predict_GNB = GNB.predict(X_test_tfidf.toarray())\n",
    "acc_GNB = accuracy_score(y_test, y_predict_GNB)\n",
    "print(\"\\nThe Training Score: {} \\n\".format(GNB.score(X_train_tfidf.toarray(),y_train)*100))\n",
    "print('The Accuracy is : {}\\n\\n'.format(acc_GNB) )\n",
    "# cm_GNB = conf_matrix(y_test, y_predict_GNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0c708",
   "metadata": {},
   "source": [
    "### Ensemble ML Algorthims:\n",
    "starting with voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c3d8b280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINIG RESULTS: \n",
      "===============================\n",
      "CONFUSION MATRIX:\n",
      "[[125   0   0   0]\n",
      " [  0 383   0   0]\n",
      " [  0  26   0   0]\n",
      " [  0   0   0  69]]\n",
      "ACCURACY SCORE:\n",
      "0.9569\n",
      "CLASSIFICATION REPORT:\n",
      "               2           7     9    10  accuracy   macro avg  weighted avg\n",
      "precision    1.0    0.936430   0.0   1.0  0.956882    0.734108      0.916505\n",
      "recall       1.0    1.000000   0.0   1.0  0.956882    0.750000      0.956882\n",
      "f1-score     1.0    0.967172   0.0   1.0  0.956882    0.741793      0.936031\n",
      "support    125.0  383.000000  26.0  69.0  0.956882  603.000000    603.000000\n",
      "TESTING RESULTS: \n",
      "===============================\n",
      "CONFUSION MATRIX:\n",
      "[[  8  48   0   0]\n",
      " [  0 198   0   0]\n",
      " [  0   9   0   0]\n",
      " [  0  26   0   8]]\n",
      "ACCURACY SCORE:\n",
      "0.7205\n",
      "CLASSIFICATION REPORT:\n",
      "                   2           7    9         10  accuracy   macro avg  \\\n",
      "precision   1.000000    0.704626  0.0   1.000000  0.720539    0.676157   \n",
      "recall      0.142857    1.000000  0.0   0.235294  0.720539    0.344538   \n",
      "f1-score    0.250000    0.826722  0.0   0.380952  0.720539    0.364419   \n",
      "support    56.000000  198.000000  9.0  34.000000  0.720539  297.000000   \n",
      "\n",
      "           weighted avg  \n",
      "precision      0.772781  \n",
      "recall         0.720539  \n",
      "f1-score       0.641897  \n",
      "support      297.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulazizalkhonain/tensorflow-test/envir/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/abdulazizalkhonain/tensorflow-test/envir/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "def evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "\n",
    "    print(\"TRAINIG RESULTS: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_train, y_train_pred, output_dict=True))\n",
    "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_train, y_train_pred)}\")\n",
    "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "\n",
    "    print(\"TESTING RESULTS: \\n===============================\")\n",
    "    clf_report = pd.DataFrame(classification_report(y_test, y_test_pred, output_dict=True))\n",
    "    print(f\"CONFUSION MATRIX:\\n{confusion_matrix(y_test, y_test_pred)}\")\n",
    "    print(f\"ACCURACY SCORE:\\n{accuracy_score(y_test, y_test_pred):.4f}\")\n",
    "    print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "    \n",
    "estimators = []\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "estimators.append(('Logistic', log_reg))\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "estimators.append(('Tree', tree))\n",
    "\n",
    "svm_clf = SVC(gamma='scale')\n",
    "estimators.append(('SVM', svm_clf))\n",
    "\n",
    "voting = VotingClassifier(estimators=estimators)\n",
    "voting.fit(X_train_tfidf, y_train)\n",
    "\n",
    "evaluate(voting, X_train_tfidf, X_test_tfidf, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e03c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
